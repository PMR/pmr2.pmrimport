#!/usr/bin/env python

import sys
import re
import os, os.path
import urllib2
import logging
from lxml import etree

from cStringIO import StringIO

from pmr2.processor.cmeta import Cmeta

HELP = """\
PMR1 Cmeta Keyword Viewer/Processor
usage: %s [-a] [<file/dir>]

  This utility will compare all the keywords in this file, and make
  recommendation as to what keywords may be missing.  The file structure
  is assumed to be generated by an accompanied shell script.

  <file>
        A CellML file that contains metadata, or an RDF file.  CellML
        metadata contain within will be printed.
  -h
        This help message.
  -a
        Do everything on <dir>
""" % os.path.basename(__file__)

args = sys.argv[1:]
if len(args) < 1:
    print HELP.splitlines()[1]
    sys.exit(1)

if '-h' in args:
    print HELP
    sys.exit(1)

def prepare_logger(loglevel=logging.ERROR):
    formatter = logging.Formatter('%(message)s')
    logger = logging.getLogger('metadata')
    handler = logging.StreamHandler()
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(loglevel)

prepare_logger()
logger = logging.getLogger('metadata')

def render_metadata(metadata):
    result = []
    ids = metadata.get_cmetaid()
    keywords = metadata.get_keywords()
    guess_id = None
    if keywords:
        guess_id = keywords[0][0]

    citation = None
    if ids:
        result.append('using model cmeta:id ')
        citation = metadata.get_citation(ids[0])
    else:
        if guess_id:
            result.append('using id guessed from keywords')
            citation = metadata.get_citation(guess_id)
        else:
            result.append('no identifiers found')

    if citation:
        citation_id = citation[0]['citation_id']
        citation_bibliographicCitation = citation[0]['journal']
        citation_title = citation[0]['title']

        authors = []
        for c in citation[0]['creator']:
            family = c['family']
            given = c['given']
            if c['other']:
                other = ' '.join(c['other'])
            else:
                other = ''
            fn = (family, given, other)
            authors.append(fn)
        citation_authors = authors
    else:
        # XXX when we can do wildcard captures, or nesting, fix here
        citation_id = '(unknown)'
        citation_bibliographicCitation = '(unknown)'
        citation_title = '(unknown)'
        citation_authors = '(unknown)'
        result.append('no citations found')

    result.append('citation id\t- %s' % citation_id)
    result.append('authors\t\t- %s' % citation_authors)
    result.append('journal\t\t- %s' % citation_bibliographicCitation)
    result.append('title\t\t- %s' % citation_title)
    result.append('keywords\t- %s' % keywords)
    #return result
    result = [i[1] for i in keywords]
    return result

def fetch_keyword(metadata):
    result = []
    ids = metadata.get_cmetaid()
    keywords = [i[1] for i in metadata.get_keywords()]
    keywords.sort()
    return keywords

def download(uri):
    try:
        fp = urllib2.urlopen(uri)
        result = fp.read()
        fp.close()
    except:
        return ''
    return result

failsuite = (
    # let's hear it for 4Suite's non-standard, non-anonymous 
    # anonymous id that tries to be an advertisement
    # should be 'rdf:about="rdf:#' because this is a PMR converter
    # and I had to work with (more like work around) 4Suite on PMR
    # so hacks like these were introduced.  Normalize everything
    # first before we convert everything to proper RDF blind nodes.
    ('rdfid', 
        re.compile('rdf:ID="#?http://4suite.org/rdf/anonymous/'),
        'rdf:about="rdf:#'
    ),
    ('failsuite', 
        re.compile('http://4suite.org/rdf/anonymous/'), 
        'rdf:#',
    ),
    # failsuite also made our CellML metadata reference an explicit
    # uri where there were none
    # <rdf:Description rdf:about="http://www.cellml.org/models/butera_rinzel_smith_1999_version01">
    ('absoulute rdf reference', 
        re.compile(
            'rdf:about="http://www.cellml.org/models/'
            '[^#"]*_[0-9]{4}_version[0-9]{2}[^#"]*'), 
        r'rdf:about="',
    ),
    # the rest without real filename, assuming they were originally
    # references to cmeta:id nodes but the rdf:about attributes did
    # not have the prepending # to signifify reference to cmeta:id.
    ('originalnotid', 
        re.compile('rdf:about="http://www.cellml.org/models/([^"#]*)"'),
        r'rdf:about="#\1"',
    ),
    # or they could be translated into file
    ('originalnotid file:///', 
        re.compile('rdf:about="file:///([^"#]*)"'),
        r'rdf:about="#\1"',
    ),
    # rdf:# fakereource (should be blind nodes) represented as literals?
    ('rdffakeresource',
        re.compile('>(rdf:#[^<]*)</[^>]*>'),
        r' rdf:resource="\1"/>',
    ),
    # should be 'rdf:about="#'
    ('rdfidid?',
        re.compile('rdf:ID="#*'),
        'rdf:about="#',
    ),
    # file:// do not belong online (the rest of them)
    ('file://',
        re.compile('="file://[^"]*(#[^"]*")'),
        r'="\1',
    ),
    # normalize nodes to rdf:#
    ('miscorrection',
        re.compile(
            '"(#[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}'
            '-[0-9a-f]{12})"'),
        r'"rdf:\1"',
    ),
    # remove the rest of the gunk
    ('miscorrection2',
        re.compile(
            'rdf:(about|resource)=".+(rdf:#[^"]*)"'),
        r'rdf:\1="\2"',
    ),
    # xmlbase (not just 4Suite)
    ('xmlbase',
        re.compile(' xml:base="[^"]*"'),
        '',
    ),
    # PCEnv absolute RDF fragments
    ('pcenv RDF:about',
        re.compile(' RDF:about="[^"]*.cellml"'),
        ' RDF:about=""',
    ),
)

def fix_failsuite(data):
    # Exorcise the remaining RDF/XML possessed by 4Suite.
    failures = failsuite
    for fail in failures:
        if fail[1].search(data):
            data = fail[1].sub(fail[2], data)
    return data

def singlerun(fn, batched=False, web=False):

    cellml_fn = fn
    keyword_fn = fn + '.keyword'    # raw key
    metadata_fn = fn + '.metadata'  # raw metadata

    try:
        cellml_fp = open(cellml_fn)
        cmlmd = Cmeta(cellml_fp)
        cellml_fp.close()
    except:
        logger.warning('%s metadata error', cellml_fn)
        cmlmd = None

    if not web:
        rawkey_fp = open(keyword_fn)
        rawkey = rawkey_fp.read().splitlines()
        rawkey_fp.close()

        rawmd_fp = open(metadata_fn)
        rawmd = Cmeta(rawmd_fp)
        rawmd_fp.close()
    else:
        # fetch data from PMR1
        keyword_uri = web + '/getPmr_keywords'    # raw key
        metadata_uri = web + '/metadata'  # raw metadata

        rawkey = download(keyword_uri)
        metadata_str = download(metadata_uri)
        cleansed = fix_failsuite(metadata_str)
        rawmd = Cmeta(StringIO(cleansed))

    #rawkey  # raw key file, needs processing
    #rawmd   # Cmeta obj of raw metadata

    if '<html' in rawkey:
        tree = etree.parse(StringIO(rawkey))
        index_keyword = [
            tree.xpath('string(/html/body)').strip(),
            tree.xpath('string(/html/head/title)').strip(),
        ]
    elif rawkey[:1] == '(':
        # XXX I am being lazy here, because this input is generated by Plone directly from the object.
        exec 'index_keyword = ' + rawkey
    else:
        index_keyword = []

    if cmlmd:
        cmlmd_keyword = fetch_keyword(cmlmd)
    else:
        cmlmd_keyword = []
    rawmd_keyword = fetch_keyword(rawmd)
    index_keyword = list(index_keyword)

    cmlmd_keyword.sort()
    rawmd_keyword.sort()
    index_keyword.sort()

    if not batched:
        print 'cellml\t\t- (%s)' % \
            (', '.join(["'%s'" % i for i in cmlmd_keyword]))
        print 'metadata\t- (%s)' % \
            (', '.join(["'%s'" % i for i in rawmd_keyword]))
        print 'indexed\t\t- (%s)' % \
            (', '.join(["'%s'" % i for i in index_keyword]))

    return index_keyword, cmlmd_keyword, rawmd_keyword


rdfkw_template = """\
<bqs:reference rdf:parseType="Resource">
  <dc:subject rdf:parseType="Resource">
    <bqs:subject_type>keyword</bqs:subject_type>
    <rdf:value>
      <rdf:Bag>
%s
      </rdf:Bag>
    </rdf:value>
  </dc:subject>
</bqs:reference>
"""

rdfkw_line = '        <rdf:li>%s</rdf:li>'
re_clean_name = re.compile('_version[0-9]{2}(.*)$')
re_version = re.compile('^[0-9]{2}$')

def process(root, versions, root_dir, real_root):

    results = []
    keywords = []
    cml = []
    frags = {}
    lastf = {}

    def rundir(path, version, root):
        cellml_files = [i for i in os.listdir(path) if i.endswith('.cellml')]

        for cellml in cellml_files:
            logger.info(cellml)
            cellml_path = os.path.join(path, cellml)
            frag = cellml[len(root):-7]
            original_name = '%s_version%s%s' % (root, version, frag)
            logger.info(original_name)
            baseuri = 'http://www.cellml.org/models/' + original_name
            ind, cml, raw = singlerun(cellml_path, batched=True, web=baseuri)

            keywords.extend(ind)
            keywords.extend(cml)
            keywords.extend(raw)

            results.append('\t%s' % original_name)
            results.append('In CellML =\t%s' % '\t'.join(cml))
            results.append('/keywords =\t%s' % '\t'.join(ind))
            results.append('/metadata =\t%s' % '\t'.join(raw))

            if frag not in frags:
                frags[frag] = set()
            frags[frag].update(ind)
            frags[frag].update(cml)
            frags[frag].update(raw)
            if '' in frags[frag]: 
                frags[frag].remove('')

            lastf[frag] = cml

        return cml

    for version in versions:
        logger.info(version)
        version_dir = os.path.join(root_dir, version)
        cml = rundir(version_dir, version, root)

    allkeywords = [i for i in set(keywords) if i]
    allkeywords.sort()
    results.append('-' * 72)
    results.append('all keywords =\t%s' % '\t'.join(allkeywords))
    results.append('-' * 72)

    if allkeywords:
        # first stage
        for k, v in frags.iteritems():
            c = set(lastf[k])
            if '' in c:
                c.remove('')

            if v == c:  # all keyword values of this variant vs this file
                rdfext = '%s.same.rdf' % k
            else:
                rdfext = '%s.diff.rdf' % k
            rdf = rdfkw_template % '\n'.join([rdfkw_line % i for i in v])
            rdffp = open(os.path.join(root_dir, version) + rdfext, 'w')
            rdffp.write(rdf)
            rdffp.close()

    rdffp = open(os.path.join(real_root, 'results.txt'), 'a')
    rdffp.write('\n'.join(results))
    rdffp.write('\n')
    rdffp.close()

def multirun(path):
    results = {}
    allkw = []

    def flush_keywords(allkw):
        if not allkw:
            # nothing to do
            return
        allkw.empty()
        # output rdf

    current_workspace = None

    roots = [i for i in os.listdir(path) if not i.startswith('.')]
    roots.sort()

    rdffp = open(os.path.join(path, 'results.txt'), 'w')
    rdffp.close()

    for root in roots:
        root_dir = os.path.join(path, root)
        if os.path.isdir(root_dir):
            logger.info(root)
            versions = [i for i in os.listdir(root_dir) if re_version.match(i)]
            versions.sort()
            process(root, versions, root_dir, path)

if '-a' in args:
    if len(args) < 2:
        print HELP.splitlines()[1]
        sys.exit(1)
    path = os.path.realpath(args.pop())
    multirun(path)
else:
    fn = os.path.realpath(args.pop())
    singlerun(fn)
